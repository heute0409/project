# 0710

## 내일 도전과제

---

1. 우리가 가진 json 파일을 preprocess 파일 사용해 따로 돌려서 train box, train, txt 파일 등을 만든다. → terminal에서 돌려도 이 파일들이 생성될 것이다. 코드를 정확히 확인해보고 실행해보자. → 실행한 뒤에는 코드를 고쳐서(좌표값8개...) 다시 실행해보자. 

# 멘토링

---

토크나이저 한 상태로 512개를 넘어가면 안 된다. (BERT 모델의 max가 512개) 

결론적으로 전처리 관계에서 tokenizer는 고려하지 않아도 된다. 코드에서 사용한 이유는 하나의 박스가 하나의 텍스트가 여러 토큰으로 분류가 될 수 있기 때문에 전체 토큰의 개수가 max 값을 넘어간다면 잘라주기 위해 호출한 것이다. (쉽게 말해서 512개가 넘어갈지 아닌지 체크하기 위해 넣은 코드!)

`line_number`는 행을 말하는 게 맞다. 신분증에 맞는 것으로 모델을 설계하고 input으로 정의해야 한다. 

terminal에서 파일을 돌려보는 걸로 해보자. 우리가 헷갈린 부분은 모델들을 통채로 돌려야 한다고 생각했기 때문에 에러가 발생하고 헤맸던 것 같다. 

`[**utils.py](http://utils.py)` 파일에 대한 설명** 

---

### parsing team

토크나이저를 사용해서 학습하게 되면 bert 모델도 다시 만들어야 할 것이다. 우리가 새로운 토큰 id를 만들겠다는 뜻이기 때문에, bert도 마찬가지로 처음부터 학습을 해줘야 쌍이 맞게 될 것이다. 

utils.py라는 파일은 클래스와 모델 세트를 지정해준다. 

추가학습 시키겠다는 것은, bert tokenizer를 새로 학습시키겠다는 것이고, 토크나이저로 bert를 학습시켜야 한다는 것이다. 이렇게 되면 해야 할 일이 굉장히 많아진다. 

멘토님 : layoutLM embedding 파일 → [POT.py](http://pot.py) (POT 파일은 멘토님의 파일) 

sequence_output으로 감성분석을 진행한다. 

`self.classifier` → `nn.Linear()` : fully connected layer처럼.. 생각하면 된다. input 차원이 10차원이라고 하더라도, 선형으로 보는 것이다. keras의 dense layer라고 보면 된다. 

### Pre-train을 쓰는 이유

어떤 모델을 사용하든 똑같은 아키텍쳐를 만들 수 있다. 하지만 어떤 모델을 만들려면 많은 양을 학습시켜야 한다. 그래서 우리는 RESNET에서 이미 train 된 모델을 가져와서 fine tuning을 하는 것이다. 우리가 이미 잘 만들어놓은 모델 아키텍쳐가 있기 때문에 우리의 목적에 맞게 fine tuning하는 게 더 효율적이다. layoutLM에서 추가로 들어간 건(classifier) 우리가 훈련한 task를 fine tuning 하기 위해서... 

# argparse, if __name__ == "__main__"

---

실습을 위해 만든 코드 (김태형)

```python
import argparse

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='a+b function')
    
    parser.add_argument('--a', type=int)
    parser.add_argument('--b', type=int)
    
    args = parser.parse_args()
    print(args.a + args.b)
```

위의 파이썬 파일을 터미널에서 실행시켜보도록 하자. 

터미널의 실행 코드는 아래와 같다. 

(해당 파일 위치에서)

```python
python 파일명.py --a 1 --b 2
```

위의 코드를 입력하면 리턴값 3이 출력된다. 

여기에서, —a 혹은 —b로 작성하지 않아도 된다. -를 하나만 붙여도 된다. 아무 문자나 붙여도 되는 건 아니므로 주의하자.

만약 주피터 환경(vs 코드 등)에서 터미널을 사용하고 싶으면 코드 앞에 느낌표(!)를 붙여주도록 하자. 

[[Python] argparse 사용법 (파이썬 인자값 추가하기)](https://brownbears.tistory.com/413)

argparse에 대한 티스토리 정리 글 (사용법)

- **ArgumentParser()**

    해당 객체에는 아래와 같이 입력받고 있습니다.

    - **prog:** 프로그램의 이름 (기본값: `sys.argv[0]`)

        기본값으로 실행한 스크립트파일명을 노출. 작성 시 스크립트 파일 대신 입력한 값이 노출

    - **usage:** 프로그램 사용법을 설명하는 문자열 (기본값: 파서에 추가된 인자로부터 만들어지는 값)

        사용방법을 노출. 기본값으로 실행한 파일 + 입력한 인자값들을 노출

    - **description:** 인자 도움말 전에 표시할 텍스트 (기본값: none)

        스크립트에 -h 옵션을 주어 실행 시, usage 아래에 노출

    - **epilog:** 인자 도움말 후에 표시할 텍스트 (기본값: none)
    - **parents:** `ArgumentParser` 객체들의 리스트이고, 이 들의 인자들도 포함
    - **formatter_class:** 도움말 출력을 사용자 정의하기 위한 클래스
    - **prefix_chars:** 선택 인자 앞에 붙는 문자 집합 (기본값: '-').
    - **fromfile_prefix_chars:** 추가 인자를 읽어야 하는 파일 앞에 붙는 문자 집합 (기본값: `None`).
    - **argument_default:** 인자의 전역 기본값 (기본값: `None`)
    - **conflict_handler:** 충돌하는 선택 사항을 해결하기 위한 전략 (일반적으로 불필요함)
    - **add_help:** 파서에 `h/--help` 옵션을 추가 (기본값: `True`)
    - **allow_abbrev:** 약어가 모호하지 않으면 긴 옵션을 축약할 수 있도록 함. (기본값: `True`)
- **add_argument()**
    - **name or flags:** 옵션 문자열의 이름이나 리스트, 예를 들어 `foo` 또는 `f, --foo`.
    - **action:** 명령행에서 이 인자가 발견될 때 수행 할 액션의 기본형.
    - **nargs:** 소비되어야 하는 명령행 인자의 수.
    - **const:** 일부 action 및 nargs 를 선택할 때 필요한 상숫값.
    - **default:** 인자가 명령행에 없는 경우 생성되는 값.
    - **type:** 명령행 인자가 변환되어야 할 형.
    - **choices:** 인자로 허용되는 값의 컨테이너.
    - **required:** 명령행 옵션을 생략 할 수 있는지 아닌지 (선택적일 때만).
    - **help:** 인자가 하는 일에 대한 간단한 설명.
    - **metavar:** 사용 메시지에 사용되는 인자의 이름.
    - **dest:** `parse_args()` 가 반환하는 객체에 추가될 어트리뷰트의 이름.

[if __name__ == "__main__"은 왜 필요할까?](https://medium.com/@chullino/if-name-main-%EC%9D%80-%EC%99%9C-%ED%95%84%EC%9A%94%ED%95%A0%EA%B9%8C-bc48cba7f720)

```python
if __name__ == "__main__" :
```

위의 코드는 해당 모듈이 import된 경우가 아니라 직접 실행된 경우, if문 이하의 코드를 돌리라는 명령이다. 

만약 이 if문이 없다면 다른 파일에서 import 했을 경우 무조건 실행된다.