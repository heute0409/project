# 0708

## 도전 과제

---

수동으로 만든 dataset으로 BERT 모델을 돌려봤다. BERT 모델의 정확한 process와 코드 해석을 하고, dataset을 어떻게 만들어야 할지 논의해보도록 한다. 

OCR을 돌리면 

![0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled.png](0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled.png)

위 사진처럼 텍스트가 찢어져서 나온다. 이러한 데이터를 어떻게 만져야 할지 멘토링 시간에 질문하고 방법을 찾도록 한다. 

현재는 1. OCR 코드를 수정한다(bounding box 부분을 뭉터기로 다시 잡는다) 2. 갖고 있는 json 파일을 csv 파일로 변환할 때 추가 전처리 작업을 진행한다. → 이 정도의 대안책이 나왔다. 

## 멘토링 내용

BERT input에 어떤 데이터를 넣어야 하는지 설계 

BERT에는 여러 task가 있다. BERT를 fine tuning 하는 과정에 task가 따로 있다. 이 뒤에 예제를 선택해야 한다.

멘토님도 이미지는 넣지 않았다
위치는 중요하기 때문에 좌표들로 positional embedding 할 수 있는 방법은 없을까?

토큰의 순서는 중요할 것이다
어떤 텍스트를 먼저 넣을지에 대한 논의 필요

text token 순서에 대해 고려해보기
굳이 텍스트의 특징만 사용할 거였으면 BERT는 사용할 필요가 없다
text 간의 유사도를 생각해서 classification 할 거였으면 다른 모델을 사용해도 된다. 굳이 BERT를 사용하지 않아도 된다.

layoutLM을 돌려서 필요 없는 걸 빼보는 방식으로 사용한다

자연어 처리에서는 텍스트와 텍스트 위치만 input으로. lm에서는 문서의 텍스트나 표, 색깔 등도 key value에 대한 특징있다는 것을 말하는 것이다. 기존의 bert 문제로 풀었는데, 전 연구에 비해서 이미지 요소도 중요하다. 이미지적인 요소, 글자체 등을 고려해서 feature를 어떻게 뽑을 것인지? bbox 안에 있는 이미지를 cnn 모델에 통과시키는 것이다. 이 ouput을 bert에 넣는 것이다. 각 토큰마다 분류할 것이다. => layoutLM
모델이 해당되는 코드... pre process.py랑 train 쪽을 ... 코드 기준으로 나눠서 역할을 나눠보는 것으로

pre trained 된 모델을 사용해야 한다 -> 이런 모델의 종류가 굉장히 많다. 이런 모델을 검색해봐야 할듯???

어떤 데이터도 어떻게 trained 됐는지 다를 것이다
일일이 다운로드 받기 힘들기 때문에 transformers 라이브러리가 유명한 pre trained된 모델을 다 갖고 있다. transformers는 허브라고 생각하면 된다. 나는 태그에 있는 pre trained 된 모델을 다운로드 받게 된다. BERT 아키텍쳐라면 태그를 보면 된다. 바뀐 태그의 pre trained 모델이 적용될 것이다.
코드에 변경을 해줄 필요는 있다. input이 조금씩 다르기 때문이다.
모델 아키텍쳐에 맞는 input을 바꿔야 할 것이다.

monologg kobert , kykim bert-kor-base
klue/bart-base

그럼 매번 labeling을 해야 하는건가???????? → json 파일에 수작업으로 labeling을 하고 학습을 시킨다. 데이터 양은 여러 각도로 찍은 신분증 사진을 사용해 좌표값을 달리 하고, 이름이나 주민번호는 랜덤으로 입력한다. 

### 코드 설명

![0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%201.png](0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%201.png)

train box, train txt, train image 

![0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%202.png](0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%202.png)

순서는 일치해야 한다. 

각 토큰에 대해서 실제 좌표, 이미지 크기, 라인 넘버, 이미지 파일 → 정보가 있다. 

각 토큰마다 정답 labeling이 되어 있다. 

폴더에 있는 모든 json이 세 가지 파일로 output 나온다. 

![0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%203.png](0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%203.png)

convert → 이 단계에서는 크게 중요한 게 없다. bbox의 크기는 이미지마다 다를 것이기 때문에 정규화 해야 한다. 

![0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%204.png](0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%204.png)

첫번째 등장하는 토큰부터 0으로 위치를 설정. 이걸 베이스로 크기를 100*100으로 잡아서, 상대적인 위치를 잡았다. 

![0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%205.png](0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%205.png)

![0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%206.png](0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%206.png)

위의 두 이미지가 serialize하는 단계로 생각한다. 생성된 라인 별로 x축 방향으로 sorting 한다. 이 데이터가 json 형태로 들어가게 된다. 

아래로 긴 코드들은 train_box.txt 형태로 만들어주는 것들이다. 

transformer 모델을 가져오면 pre train된 모델을 확인할 수 있다. 찾기 힘드니까! [utils.py](http://utils.py) 파일에서 확인해보자. 

![0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%207.png](0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%207.png)

BERTforclassification 을 보면 될 것이다 

토큰별로 fine tuning하는 걸 보려면 POTBERTForTokenClassification을 서치해야 잘 나올 것이다. 

XLMrobert 코드는 전부 무시해도 된다. 

bertfortokenclassification를 바꾸는 코드가 조금 들어갔다. (input 형태가 바뀌어야 하기 때문)

potembedding → bert에 들어가야 하는 토큰, 라인 넘버 등을 벡터로 바꿔야 하는데 이걸 위해 embedding 하는 단계 → 마치면 벡터들의 조합으로 바뀔 것이다 

바뀌는 input에 대한 embedding, 아키텍쳐 부분들이 있고, bert 모델을 활용해서 토큰 classification으로 바뀌어야 하는 부분으을 위주로 코드를 봐야 한다. 

우리는 input을 어떻게 넣을지 합의를 해야 한다. 이 파일에 몇 번째 트레인 할 수 있는 데이터를 어떤 포맷으로 줄 지 논의를 해야 한다. 모델이랑 train할 코드의 경우에는 그 다음으로 생각하고, 여기까지가 전처리이기 때문에 일단 다음주부터 train을 하자! 

왜 무게중심으로 하자고 언급???? 

![0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%208.png](0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%208.png)

![0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%209.png](0708%201ca6ae9248ce4f648319eb33b58f5e57/Untitled%209.png)

디렉토리 위치는 수정해야함 

## 정리

---

- **질문**
1. BERT input에 어떤 데이터를 넣어야 하는지 설계한다.
2. 토큰의 위치(좌표)로 positional embedding을 한다. -> 어떤 텍스트를 먼저 넣을지 논의한다.
- **멘토링 내용 정리**
1. LayoutLM은 텍스트 외에도 문서 이미지의 색, 표 등도 특징이 있다는 가정 하에 만들어진 모델이다. 즉, 이미지적인 요소를 고려해서 어떻게 feature를 뽑을지 논의해야 한다. (bbox 안에 있는 이미지를 cnn 모델로 돌리는 것 -> 이때 나온 output을 BERT에 넣는다.)
2. 매번 labeling을 해야 하는가? -> json 파일에 수작업으로 labeling을 하고 학습을 시킨다. 데이터 양은 여러 각도로 찍은 신분증 사진을 사용해 좌표값을 달리하고, 이름이나 주민번호는 랜덤 코드를 사용해 입력한다.